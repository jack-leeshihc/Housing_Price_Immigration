{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1e3b11",
   "metadata": {},
   "source": [
    "# ECO475 Group 2 Notebook Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9423e14",
   "metadata": {},
   "source": [
    "### Author: Shih-Chieh Lee, Lingyun Ma, Yuwen Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e39c6",
   "metadata": {},
   "source": [
    "# 1. Basic Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d997882",
   "metadata": {},
   "source": [
    "## a. Package Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d533b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stats-can\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install statsmodels\n",
    "#!pip install linearmodels\n",
    "#!pip install tabula-py #Note: Pls install tabula-py, not tabula——血的教训\n",
    "#!pip install warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c7ae7",
   "metadata": {},
   "source": [
    "## b. Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2793827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection Packages\n",
    "from stats_can import StatsCan #read StatsCan data \n",
    "\n",
    "\n",
    "sc = StatsCan(data_folder=\"/Users/changanlee/Documents/GitHub/Housing_Price_Immigration/Input\") \n",
    "#Create an instance of StatsCan class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de264bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tabula and check java environment\n",
    "from tabula.io import read_pdf  #Scrape table from pdf files\n",
    "import requests \n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74954897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Packages\n",
    "import pandas as pd #pandas\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #data visualization\n",
    "%matplotlib inline\n",
    "# activate plot theme\n",
    "import qeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9066ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats Model Packages\n",
    "import statsmodels.api as sm # statistical model\n",
    "from statsmodels.iolib.summary2 import summary_col # summary table for regression result\n",
    "from linearmodels.iv import IV2SLS # IV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "63af4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence all the warnings cuz they're absolutely annoying if you loop it multiple times\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36ab2f",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f60218",
   "metadata": {},
   "source": [
    "## A. StatsCan Population Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f689ff6",
   "metadata": {},
   "source": [
    "Let's start with datasets from Statistics Canada, as it's earier to collect directly using StatsCan library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74164688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GEO</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78033</th>\n",
       "      <td>2016</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>111467.0</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78034</th>\n",
       "      <td>2016</td>\n",
       "      <td>Conception Bay South</td>\n",
       "      <td>26810.0</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78035</th>\n",
       "      <td>2016</td>\n",
       "      <td>Mount Pearl</td>\n",
       "      <td>23596.0</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78036</th>\n",
       "      <td>2016</td>\n",
       "      <td>Paradise</td>\n",
       "      <td>22023.0</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78037</th>\n",
       "      <td>2016</td>\n",
       "      <td>Corner Brook</td>\n",
       "      <td>20155.0</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114439</th>\n",
       "      <td>2022</td>\n",
       "      <td>Baffin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unorganized (NO), Nunavut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114440</th>\n",
       "      <td>2022</td>\n",
       "      <td>Keewatin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unorganized (NO), Nunavut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114441</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bathurst Inlet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nunavut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114442</th>\n",
       "      <td>2022</td>\n",
       "      <td>Umingmaktok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nunavut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114443</th>\n",
       "      <td>2022</td>\n",
       "      <td>Kitikmeot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unorganized (NO), Nunavut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36134 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year                   GEO     VALUE                   Province\n",
       "78033   2016            St. John's  111467.0  Newfoundland and Labrador\n",
       "78034   2016  Conception Bay South   26810.0  Newfoundland and Labrador\n",
       "78035   2016           Mount Pearl   23596.0  Newfoundland and Labrador\n",
       "78036   2016              Paradise   22023.0  Newfoundland and Labrador\n",
       "78037   2016          Corner Brook   20155.0  Newfoundland and Labrador\n",
       "...      ...                   ...       ...                        ...\n",
       "114439  2022                Baffin       0.0  Unorganized (NO), Nunavut\n",
       "114440  2022              Keewatin       0.0  Unorganized (NO), Nunavut\n",
       "114441  2022        Bathurst Inlet       0.0                    Nunavut\n",
       "114442  2022           Umingmaktok       0.0                    Nunavut\n",
       "114443  2022             Kitikmeot       0.0  Unorganized (NO), Nunavut\n",
       "\n",
       "[36134 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pop = sc.table_to_df(\"17-10-0142-01\")\n",
    "Pop = Pop[[\"REF_DATE\",\"GEO\",\"VALUE\"]]\n",
    "Pop['REF_DATE'] = pd.to_datetime(Pop['REF_DATE'])\n",
    "\n",
    "Pop = Pop[Pop['GEO'].str.contains('\\\\(')]\n",
    "Pop[['GEO', 'Province']] = Pop['GEO'].str.split(',', expand=True, n=1)\n",
    "Pop['GEO'] = Pop['GEO'].str.strip()\n",
    "Pop['Province'] = Pop['Province'].str.strip()\n",
    "Pop['GEO'] = Pop['GEO'].str.replace(r'\\s*\\(.*\\)', '', regex=True)\n",
    "\n",
    "\n",
    "Pop['REF_DATE']= Pop['REF_DATE'].dt.year.astype(int)\n",
    "Pop = Pop[Pop['REF_DATE'] >= 2016]\n",
    "Pop = Pop.rename(columns = {\"REF_DATE\":\"Year\"})\n",
    "Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fb044d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GEO</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>2819399.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>964341.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>746352.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>Brampton</td>\n",
       "      <td>617571.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>552272.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>2022</td>\n",
       "      <td>Nedoats 11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>2022</td>\n",
       "      <td>Babine Lake 21B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>2022</td>\n",
       "      <td>Mission Lands 17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>2022</td>\n",
       "      <td>Good Hope Lake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>2022</td>\n",
       "      <td>Kahntah 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9044 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year               GEO      VALUE          Province\n",
       "0     2016           Toronto  2819399.0           Ontario\n",
       "1     2016            Ottawa   964341.0           Ontario\n",
       "2     2016       Mississauga   746352.0           Ontario\n",
       "3     2016          Brampton   617571.0           Ontario\n",
       "4     2016          Hamilton   552272.0           Ontario\n",
       "...    ...               ...        ...               ...\n",
       "9039  2022        Nedoats 11        0.0  British Columbia\n",
       "9040  2022   Babine Lake 21B        0.0  British Columbia\n",
       "9041  2022  Mission Lands 17        0.0  British Columbia\n",
       "9042  2022    Good Hope Lake        0.0  British Columbia\n",
       "9043  2022         Kahntah 3        0.0  British Columbia\n",
       "\n",
       "[9044 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take out observations in BC & ON\n",
    "\n",
    "Pop_ON_BC = Pop[Pop[\"Province\"].isin([\"British Columbia\", \"Ontario\"])]\n",
    "Pop_ON_BC.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b5db2e",
   "metadata": {},
   "source": [
    "## B. CREA Monthly House Price Index Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb565e",
   "metadata": {},
   "source": [
    "### 1) Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6051a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define func to generate URLs based on months and years\n",
    "def generate_url(month, year, cma):\n",
    "    if cma == \"Toronto\":\n",
    "        if month < 10:\n",
    "            return f\"https://trreb.ca/files/market-stats/home-price-index/TREB_MLS_HPI_Public_Tables_0{month}{year}.pdf\"\n",
    "        else:\n",
    "            return f\"https://trreb.ca/files/market-stats/home-price-index/TREB_MLS_HPI_Public_Tables_{month}{year}.pdf\"\n",
    "            #return the corresponding GTA HPI monthly report pdf for scrapping\n",
    "    elif cma == \"Vancouver\":\n",
    "        url = generate_url_van(month, year)\n",
    "        return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8396cff",
   "metadata": {},
   "source": [
    "### 1) GTA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636edef",
   "metadata": {},
   "source": [
    "#### a) Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0be6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define func to extract table from pdf monthly report & data cleaning\n",
    "def extract_table(url, month, year):\n",
    "\n",
    "    # Extract table from pdf\n",
    "    tables = read_pdf(url, pages=\"2\", lattice = \"True\", multiple_tables = \"False\", \n",
    "                      area = [10,0,97,100],relative_area = \"True\", silent = \"True\") \n",
    "        # Note: lattice should be set as True for our case \n",
    "            #to read everything on page 2 as one table\n",
    "            \n",
    "    table = tables[0]\n",
    "    \n",
    "    # Clean the data table\n",
    "    new_header = table.iloc[0] # Set new header with the first row of the table\n",
    "    table = table[1:]  # Take the data below the header row\n",
    "    table.columns = new_header  # Set the new header\n",
    "    \n",
    "    # We only want data about composite / residential property, which is the first four columns\n",
    "    table = table.iloc[:, :4]\n",
    "    \n",
    "    # Rename the first column to \"Location\" \n",
    "    table = table.rename(columns={table.columns[0]: \"Location\"})\n",
    "\n",
    "    # New Column for Month-Year\n",
    "    if month < 10:\n",
    "        table[\"Month_Year\"] = f'0{month}_20{year}'\n",
    "    else:\n",
    "        table[\"Month_Year\"] = f'{month}_20{year}'\n",
    "        \n",
    "    table.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a798a2",
   "metadata": {},
   "source": [
    "#### b) Loop to Scrape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "cma = \"Toronto\"\n",
    "\n",
    "for year in range(16, 23):\n",
    "    if year != 22:\n",
    "        for month in range(1, 13):\n",
    "            url = generate_url(month, year, cma)\n",
    "            extracted_data = extract_table(url, month, year)\n",
    "        \n",
    "            if extracted_data is not None:\n",
    "                extracted_data.reset_index(drop = True, inplace = True)\n",
    "                data_list.append(extracted_data)\n",
    "\n",
    "    else:\n",
    "        for month in range(1, 6):\n",
    "            url = generate_url(month, year)\n",
    "            extracted_data = extract_table(url, month, year)\n",
    "        \n",
    "            if extracted_data is not None:\n",
    "                extracted_data.reset_index(drop = True, inplace = True)\n",
    "                data_list.append(extracted_data)\n",
    "            \n",
    "HPI_GTA = pd.concat(data_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_GTA.to_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Raw Data/HPI_GTA.csv\",\n",
    "               index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce949554",
   "metadata": {},
   "source": [
    "For some pdf formatting reasons that I cannot solve right now, the last monthly report that can be extracted using read_pdf is May 2022. May need to mannually extract the rest of the data. See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take June 2022 for example\n",
    "\n",
    "url = generate_url(6,22) \n",
    "tables = read_pdf(url, pages = \"2\", lattice = \"True\", multiple_tables = \"False\", area = [10,0,97,100],relative_area = \"True\")\n",
    "tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0261f27",
   "metadata": {},
   "source": [
    "The column heading format is correct, but the value it reads is completely nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1c391",
   "metadata": {},
   "source": [
    "Whatever... Let's move on to GTA data first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac91bd5",
   "metadata": {},
   "source": [
    "### 2) GVA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d942b",
   "metadata": {},
   "source": [
    "First of all, Jan. 2016 ~ July 2016 monthly report is missing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3991ac",
   "metadata": {},
   "source": [
    "Second, GVA report url has multiple formats over time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8050d6",
   "metadata": {},
   "source": [
    "https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/REBGV-Stats-Pkg-August-2016.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a939c79",
   "metadata": {},
   "source": [
    "https://www.gvrealtors.ca/content/dam/rebgv_org_content/monthly-market-reports/2018-Dec-stats-pkg.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada2bca",
   "metadata": {},
   "source": [
    "https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/marketwatch/monthly_reports/REBGV-Stats-Pkg-November-2019-F.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb207110",
   "metadata": {},
   "source": [
    "OK, let's try accessing the report using all 3 formats for all month-year combination and see how it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ea6bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_url_van(month, year):\n",
    "\n",
    "    # Define the base URLs for each format\n",
    "    base_urls = [\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/monthly-market-reports/{Year}-{Month}-stats-pkg.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/marketwatch/monthly_reports/REBGV-Stats-Pkg-{Month}-{Year}-F.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/REBGV-Stats-Pkg-{Month}-{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/REBGV-Stats-Package-{Month}-{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/REBGV-Stats-Pkg-{Month}-{Year}-Updated%20HPI.pdf\",\n",
    "        \"https://members.rebgv.org/news/REBGV-Stats-Pkg-{Month}-{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/REBGV-Stats-Pkg-{Month}-{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/{YearMonth}-REBGV-Stats-Pkg-{Month}-{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/REBGV%20Stats%20Package%20{Month}%20{Year}.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/{Year}-01-{Month}-Stats-Package.pdf\",\n",
    "        \"https://www.gvrealtors.ca/content/dam/rebgv_org_content/pdfs/monthly-stats-packages/{Year}-01-{Month}-Stats--Package.pdf\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Get the month name and abbreviation\n",
    "    year = 2000 + year\n",
    "    month_name = calendar.month_name[month]\n",
    "    month_abbr = calendar.month_abbr[month]\n",
    "    year_month = f\"{year}{month:02d}\"\n",
    "\n",
    "    # Iterate through each URL pattern\n",
    "    for base_url in base_urls:\n",
    "        # Replace placeholders in the URL pattern\n",
    "        url_1 = base_url.format(Year=str(year), Month=month_name, YearMonth=year_month)\n",
    "        url_2 = base_url.format(Year=str(year), Month=month_abbr, YearMonth=year_month)\n",
    "\n",
    "        # Try fetching the first URL\n",
    "        if requests.get(url_1).status_code == 200:\n",
    "            return url_1\n",
    "\n",
    "        # Try fetching the second URL if the first one fails\n",
    "        elif requests.get(url_2).status_code == 200:\n",
    "            return url_2\n",
    "\n",
    "        # Special case for September URLs\n",
    "        if month == 9:\n",
    "            url_3 = base_url.format(Year=str(year), Month=\"Sept\", YearMonth=year_month)\n",
    "            if requests.get(url_3).status_code == 200:\n",
    "                return url_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c893afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_van(url, month, year):    \n",
    "    tables = read_pdf(url, pages = \"3\", multiple_tables = \"False\")\n",
    "    \n",
    "    if not tables or tables[0].empty:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        table = tables[0]\n",
    "        new_header = table.iloc[1] # Set new header with the second row of the table\n",
    "        new_header[0] = \"Property Type\"\n",
    "        new_header[1] = \"Location\"\n",
    "        table = table[2:]  # Take the data below the header row\n",
    "        table.columns = new_header\n",
    "\n",
    "        end_here_index = (table['Property Type'] == 'Single Family Detached').idxmax()\n",
    "        table = table.iloc[:end_here_index, 1:]\n",
    "\n",
    "        number_of_rows = len(table)\n",
    "        table = table.iloc[: number_of_rows - 2] \n",
    "        # For some reason, the last two rows are irrelevant info that we need to exclude\n",
    "        \n",
    "        if month < 10:\n",
    "            table[\"Month_Year\"] = f'0{month}_{year}'\n",
    "        else:\n",
    "            table[\"Month_Year\"] = f'{month}_{year}'\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2f3bb9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hn/gfxxh51d76nbszjdcrp5pzy80000gn/T/ipykernel_83317/2354799377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Vancouver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mextracted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_table_van\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextracted_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hn/gfxxh51d76nbszjdcrp5pzy80000gn/T/ipykernel_83317/1673826972.py\u001b[0m in \u001b[0;36mextract_table_van\u001b[0;34m(url, month, year)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_table_van\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tabula/io.py\u001b[0m in \u001b[0;36mread_pdf\u001b[0;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, force_subprocess, options)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         output = _run(\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mtabula_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mjava_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tabula/io.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(options, java_options, path, encoding, force_subprocess)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"java_options is ignored until rebooting the Python process.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tabula_vm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_tabula_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tabula/backend.py\u001b[0m in \u001b[0;36mcall_tabula_java\u001b[0;34m(self, options, path)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             result = subprocess.run(\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1977\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "cma = \"Vancouver\"\n",
    "\n",
    "for year in range(16, 24):\n",
    "    for month in range (1,13):\n",
    "        \n",
    "        url = generate_url(month, year, \"Vancouver\")\n",
    "        if url is not None:\n",
    "            extracted_data = extract_table_van(url, month, year)\n",
    "\n",
    "            if extracted_data is not None:\n",
    "                extracted_data.reset_index(drop=True, inplace=True)\n",
    "                data_list.append(extracted_data)\n",
    "\n",
    "HPI_GVA = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "columns_name = [\"Location\", \"Price\", \"Index\", \"%1M_Change\", \"%3M_Change\", \"%6M_Change\", \n",
    "               \"%1Y_Change\", \"%3Y_Change\", \"%5Y_Change\", \"%10Y_Change\", \"Month_Year\"]\n",
    "\n",
    "HPI_GVA.columns = columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29cc31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_GVA.to_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Raw Data/HPI_GVA.csv\",\n",
    "               index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802ebd1",
   "metadata": {},
   "source": [
    "# 3. Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92562c",
   "metadata": {},
   "source": [
    "In this section, we will create the research dataset for our regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e207a",
   "metadata": {},
   "source": [
    "## A. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc20d0",
   "metadata": {},
   "source": [
    "Our algorithm-read dataset comes with some missing observations / errors due to OCR limitation. We have addressed these issues mannually on Excel. Here we will load the complete datasets directly from my local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76784864",
   "metadata": {},
   "source": [
    "### 1) Read GTA & GVA Housing Price Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f5ec377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_GTA = pd.read_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Data/Raw/HPI_GTA_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c43d719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_GVA = pd.read_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Data/Raw/HPI_GVA_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b606f",
   "metadata": {},
   "source": [
    "### 2) Drop Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34811b4b",
   "metadata": {},
   "source": [
    "For both GTA and GVA housing price dataset, we will only keep columns containing basic info: Location, Index, Benchmark Price (in Canadian dollar term), and Month-Year. Other columns like growth rates will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3f6e5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTA Data\n",
    "HPI_GTA = HPI_GTA.iloc[:,:5].drop(columns=[\"Yr./Yr. % Chg.\"])\n",
    "\n",
    "HPI_GTA[\"Region\"] = \"GTA\"\n",
    "\n",
    "#GVA Data\n",
    "HPI_GVA = HPI_GVA.drop(columns=[\"%1M_Change\",\"%3M_Change\",\"%6M_Change\",\"%1Y_Change\", \"%3Y_Change\", \"%5Y_Change\", \"%10Y_Change\"])\n",
    "    # Drop columns about change rate \n",
    "\n",
    "HPI_GVA = HPI_GVA.rename(columns={\"Price\":\"Benchmark\"})\n",
    "    # Rename column name for appending\n",
    "\n",
    "HPI_GVA[\"Month_Year\"] = HPI_GVA[\"Month_Year\"].str[:3] + \"20\" + HPI_GVA[\"Month_Year\"].str[-2:]\n",
    "    # Change the Month_Year format to match the GTA dataset\n",
    "    \n",
    "HPI_GVA[\"Region\"] = \"GVA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e1520",
   "metadata": {},
   "source": [
    "### 3) Location Naming Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a56d3",
   "metadata": {},
   "source": [
    "Some of the Location names from CREA is different from the StatCan data official naming.\n",
    "\n",
    "For example, in CREA data, Toronto is referred as \"City of Toronto\" whereas in the StatsCan dataset it's simply called \"Toronto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ef1ff5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GTA location naming:\n",
    "\n",
    "HPI_GTA[\"Location\"] = HPI_GTA['Location'].str.replace(r'Region|City of |Township of ', '', regex=True)\n",
    "    # Convert \"City of Toronto\" / \"Town of XXXXXX\" to simply the name of itself\n",
    "    \n",
    "HPI_GTA.loc[HPI_GTA['Location'] == \"Bradford West\", \"Location\"] = \"Bradford West Gwillimbury\"\n",
    "HPI_GTA.loc[HPI_GTA['Location'] == \"GEswsiallimbury\", 'Location'] = \"East Gwillimbury\"\n",
    "HPI_GTA.loc[HPI_GTA['Location'] == \"EGswsiallimbury\", 'Location'] = \"East Gwillimbury\"\n",
    "    # Some unmatchable names identified mannually\n",
    "\n",
    "HPI_GTA['Location'] = HPI_GTA['Location'].str.strip()\n",
    "    # Strip to avoid unmathed case due to leading / ending space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd6b72b",
   "metadata": {},
   "source": [
    "For GVA region, it's a more percular issue. The Greater Vancouver Realtors (GVR) has split some Census Subdivisions (CSDs)into smaller custom regions. Also, there is some other naming issues as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d3ba8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GVA location naming:\n",
    "HPI_GVA[\"Location\"] = HPI_GVA['Location'].str.replace(r'Region|City of |Township of ', '', regex=True)\n",
    "    # Convert \"City of Vancouver\" / \"Town of XXXXXX\" to simply the name of itself\n",
    "\n",
    "HPI_GVA.loc[HPI_GVA['Location'] == \"Ladner\", \"Location\"] = \"Delta\"\n",
    "    # Ladner is called Delta in Census Subdivision\n",
    "    \n",
    "    \n",
    "HPI_GVA['Location'] = HPI_GVA['Location'].str.strip()\n",
    "    # Strip to avoid unmathed case due to leading / ending space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a309993",
   "metadata": {},
   "source": [
    "### 4) GVA Data Only: aggregate HPI to CSD level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae124e",
   "metadata": {},
   "source": [
    "For CSD Vancouver and CSD Burnaby, the GVRealtor has arbitrarily splitted them into several smaller districts that cannot be merged at CSD level. \n",
    "\n",
    "After identifying this issue, we notice that this question is solved through mannual GIS mapping in literature (West & Botsch, 2020). However, given the unavailability of data and our project's time limit, we have decided to take simple average of [\"Burnaby East\", \"Burnaby North\",\"Burnaby South\"] for CSD Burnaby and [\"Vancouver East\", \"Vancouver West\"] for CSD Vancouver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dfbcd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out Targeted Locations into Separate dataframes\n",
    "Vancouver_only = HPI_GVA[HPI_GVA[\"Location\"].isin([\"Vancouver East\", \"Vancouver West\"])]\n",
    "Burnaby_only = HPI_GVA[HPI_GVA[\"Location\"].isin([\"Burnaby East\", \"Burnaby North\",\"Burnaby South\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1e78fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby Month_Year and Take Average\n",
    "\n",
    "vancouver_means = Vancouver_only.groupby('Month_Year').agg({'Benchmark': 'mean', 'Index': 'mean'}).reset_index()\n",
    "\n",
    "vancouver_means['Location'] = 'Vancouver'\n",
    "vancouver_means['Region'] = 'GVA'\n",
    "\n",
    "\n",
    "burnaby_means = Burnaby_only.groupby('Month_Year').agg({'Benchmark': 'mean', 'Index': 'mean'}).reset_index()\n",
    "\n",
    "burnaby_means['Location'] = 'Burnaby'\n",
    "burnaby_means['Region'] = 'GVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6ba7ffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Index</th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>9.391260e+05</td>\n",
       "      <td>231.550000</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>1.068500e+06</td>\n",
       "      <td>264.300000</td>\n",
       "      <td>01_2017</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>1.224800e+06</td>\n",
       "      <td>303.100000</td>\n",
       "      <td>01_2018</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>1.143800e+06</td>\n",
       "      <td>283.200000</td>\n",
       "      <td>01_2019</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>1.165100e+06</td>\n",
       "      <td>288.550000</td>\n",
       "      <td>01_2020</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>9.088700e+05</td>\n",
       "      <td>260.763333</td>\n",
       "      <td>12_2019</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>9.586437e+05</td>\n",
       "      <td>274.983333</td>\n",
       "      <td>12_2020</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>1.120108e+06</td>\n",
       "      <td>312.863333</td>\n",
       "      <td>12_2021</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>1.034631e+06</td>\n",
       "      <td>332.323333</td>\n",
       "      <td>12_2022</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>1.082933e+06</td>\n",
       "      <td>345.800000</td>\n",
       "      <td>12_2023</td>\n",
       "      <td>GVA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location     Benchmark       Index Month_Year Region\n",
       "2112  Vancouver  9.391260e+05  231.550000    01_2016    GVA\n",
       "2113  Vancouver  1.068500e+06  264.300000    01_2017    GVA\n",
       "2114  Vancouver  1.224800e+06  303.100000    01_2018    GVA\n",
       "2115  Vancouver  1.143800e+06  283.200000    01_2019    GVA\n",
       "2116  Vancouver  1.165100e+06  288.550000    01_2020    GVA\n",
       "...         ...           ...         ...        ...    ...\n",
       "2299    Burnaby  9.088700e+05  260.763333    12_2019    GVA\n",
       "2300    Burnaby  9.586437e+05  274.983333    12_2020    GVA\n",
       "2301    Burnaby  1.120108e+06  312.863333    12_2021    GVA\n",
       "2302    Burnaby  1.034631e+06  332.323333    12_2022    GVA\n",
       "2303    Burnaby  1.082933e+06  345.800000    12_2023    GVA\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate back to GVA dataset\n",
    "\n",
    "HPI_GVA = pd.concat([HPI_GVA, vancouver_means, burnaby_means], ignore_index=True)\n",
    "\n",
    "HPI_GVA.loc[(HPI_GVA[\"Location\"] == \"Vancouver\") | (HPI_GVA[\"Location\"] == \"Burnaby\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de563e0",
   "metadata": {},
   "source": [
    "### 5) Merge Housing Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eb20d094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPI_Overall = pd.concat([HPI_GTA, HPI_GVA],ignore_index = True)\n",
    "HPI_Overall.to_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Data/Intermediate/HPI_Overall_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec179bd2",
   "metadata": {},
   "source": [
    "Lastly, we need to get a new \"Year\" column given that the Population data is recorded on **Annual** instead of monthly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f800eb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Index</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREB Total</td>\n",
       "      <td>190.4</td>\n",
       "      <td>581100</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halton</td>\n",
       "      <td>206.6</td>\n",
       "      <td>675800</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burlington</td>\n",
       "      <td>202.9</td>\n",
       "      <td>601200</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Halton Hills</td>\n",
       "      <td>184.5</td>\n",
       "      <td>537300</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton</td>\n",
       "      <td>210.4</td>\n",
       "      <td>580500</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location  Index Benchmark Month_Year Region Month  Year\n",
       "0    TREB Total  190.4    581100    01_2016    GTA    01  2016\n",
       "1        Halton  206.6    675800    01_2016    GTA    01  2016\n",
       "2    Burlington  202.9    601200    01_2016    GTA    01  2016\n",
       "3  Halton Hills  184.5    537300    01_2016    GTA    01  2016\n",
       "4        Milton  210.4    580500    01_2016    GTA    01  2016"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPI_Overall[[\"Month\",\"Year\"]] = HPI_Overall['Month_Year'].str.split('_', expand=True, n=1)\n",
    "HPI_Overall = HPI_Overall[HPI_Overall[\"Year\"] !=\"2023\"]\n",
    "HPI_Overall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9ba66",
   "metadata": {},
   "source": [
    "## B. Merge HPI & Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252df160",
   "metadata": {},
   "source": [
    "### 1) Left Join: a merge based on housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1ac5894f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hn/gfxxh51d76nbszjdcrp5pzy80000gn/T/ipykernel_83317/754595154.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pop_ON_BC[\"Year\"] = Pop_ON_BC[\"Year\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "Pop_ON_BC[\"Year\"] = Pop_ON_BC[\"Year\"].astype(str)\n",
    "Pop_HPI = HPI_Overall.merge(Pop_ON_BC, how=\"left\", left_on=[\"Location\", \"Year\"], right_on=[\"GEO\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e3d6aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pop_HPI.to_csv(\"/Users/changanlee/Desktop/University/Undergrad/4th-Year/Winter Semester/ECO475/Term Paper/Data/Intermediate/Population_HPI_merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487c1d2",
   "metadata": {},
   "source": [
    "### 2) Examine Unmerged cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29622616",
   "metadata": {},
   "source": [
    "Let's see what locations in CREA HPI dataset is unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "96038e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Index</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>GEO</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Location, Index, Benchmark, Month_Year, Region, Month, Year, GEO, VALUE, Province]\n",
       "Index: []"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unmerged_dataset = Pop_HPI[Pop_HPI[\"GEO\"].isna()]\n",
    "\n",
    "\n",
    "# Find rows where \"Location\" matches the specified values\n",
    "unmatched_rows_to_ignore = Unmerged_dataset[Unmerged_dataset[\"Location\"].isin([\"TREB Total\",\"Halton\", \"Peel\", \"York\", \"Durham\", \"Dufferin County\", \"Simcoe County\",\"Lower Mainland\", \"Greater Vancouver\", \"Sunshine Coast\", \"Vancouver East\", \"Vancouver West\", \"Burnaby East\", \"Burnaby North\",\"Burnaby South\"])].index\n",
    "    #The identification of these \"ignoreable\" unmatched cases are either \n",
    "        #1) identified and has been address previously\n",
    "        #or 2) represent a geographic region that is aggregated at a higher level rather than CSD (e.g.: GTA, York Region)\n",
    "\n",
    "# Drop these rows\n",
    "Unmerged_dataset = Unmerged_dataset.drop(unmatched_rows_to_ignore)\n",
    "\n",
    "Unmerged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ef2b1",
   "metadata": {},
   "source": [
    "The fact that we don't have any value in the Unmerged_dataset shows that all the possible observations have been successfully merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad25f9",
   "metadata": {},
   "source": [
    "### 3) Population-HPI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2326b0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Index</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>GEO</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREB Total</td>\n",
       "      <td>190.4</td>\n",
       "      <td>581100</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halton</td>\n",
       "      <td>206.6</td>\n",
       "      <td>675800</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burlington</td>\n",
       "      <td>202.9</td>\n",
       "      <td>601200</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>188387.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Halton Hills</td>\n",
       "      <td>184.5</td>\n",
       "      <td>537300</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Halton Hills</td>\n",
       "      <td>62944.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milton</td>\n",
       "      <td>210.4</td>\n",
       "      <td>580500</td>\n",
       "      <td>01_2016</td>\n",
       "      <td>GTA</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Milton</td>\n",
       "      <td>114276.0</td>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>272.65</td>\n",
       "      <td>950630.333333</td>\n",
       "      <td>12_2018</td>\n",
       "      <td>GVA</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>249676.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>260.763333</td>\n",
       "      <td>908870.0</td>\n",
       "      <td>12_2019</td>\n",
       "      <td>GVA</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>254518.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>274.983333</td>\n",
       "      <td>958643.666667</td>\n",
       "      <td>12_2020</td>\n",
       "      <td>GVA</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>257851.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>312.863333</td>\n",
       "      <td>1120107.666667</td>\n",
       "      <td>12_2021</td>\n",
       "      <td>GVA</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>260961.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>Burnaby</td>\n",
       "      <td>332.323333</td>\n",
       "      <td>1034630.666667</td>\n",
       "      <td>12_2022</td>\n",
       "      <td>GVA</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>270264.0</td>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5292 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Location       Index       Benchmark Month_Year Region Month  Year  \\\n",
       "0       TREB Total       190.4          581100    01_2016    GTA    01  2016   \n",
       "1           Halton       206.6          675800    01_2016    GTA    01  2016   \n",
       "2       Burlington       202.9          601200    01_2016    GTA    01  2016   \n",
       "3     Halton Hills       184.5          537300    01_2016    GTA    01  2016   \n",
       "4           Milton       210.4          580500    01_2016    GTA    01  2016   \n",
       "...            ...         ...             ...        ...    ...   ...   ...   \n",
       "5287       Burnaby      272.65   950630.333333    12_2018    GVA    12  2018   \n",
       "5288       Burnaby  260.763333        908870.0    12_2019    GVA    12  2019   \n",
       "5289       Burnaby  274.983333   958643.666667    12_2020    GVA    12  2020   \n",
       "5290       Burnaby  312.863333  1120107.666667    12_2021    GVA    12  2021   \n",
       "5291       Burnaby  332.323333  1034630.666667    12_2022    GVA    12  2022   \n",
       "\n",
       "               GEO     VALUE          Province  \n",
       "0              NaN       NaN               NaN  \n",
       "1              NaN       NaN               NaN  \n",
       "2       Burlington  188387.0           Ontario  \n",
       "3     Halton Hills   62944.0           Ontario  \n",
       "4           Milton  114276.0           Ontario  \n",
       "...            ...       ...               ...  \n",
       "5287       Burnaby  249676.0  British Columbia  \n",
       "5288       Burnaby  254518.0  British Columbia  \n",
       "5289       Burnaby  257851.0  British Columbia  \n",
       "5290       Burnaby  260961.0  British Columbia  \n",
       "5291       Burnaby  270264.0  British Columbia  \n",
       "\n",
       "[5292 rows x 10 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pop_HPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b02b07",
   "metadata": {},
   "source": [
    "Looks good! The next step will be merging the immigration census stats to the main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa9968",
   "metadata": {},
   "source": [
    "## C. Merge Immigration Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
